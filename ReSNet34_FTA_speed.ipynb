{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rafi076/RTFER/blob/main/ReSNet34_FTA_speed.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtOossuhIYOD"
      },
      "source": [
        "Block 0 — Setup & Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFnD893TIP4d",
        "outputId": "9dcdd9a2-1d24-4766-9e6a-97896c01bd4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        }
      ],
      "source": [
        "# Block 0: Setup & Imports\n",
        "import os, zipfile, random, copy\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import cv2\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms, datasets, models\n",
        "\n",
        "from torch.optim import AdamW\n",
        "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
        "\n",
        "# Reproducibility\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed); np.random.seed(seed); torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False  # set True for a bit more speed (less reproducible)\n",
        "\n",
        "set_seed(42)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pxAe1X8yIbyB"
      },
      "source": [
        "Block 1 — Access ZIP & Detect Folders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxKZt3vJIciR",
        "outputId": "4f2d2a62-1805-4adb-e30c-cbf77b733411"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Base folder detected: /content/FER-2013/FER-2013\n",
            "Official splits found: False\n",
            "TRAIN_DIR: /content/FER-2013/FER-2013/train\n",
            "VAL_DIR:   /content/FER-2013/FER-2013/train\n",
            "TEST_DIR:  /content/FER-2013/FER-2013/test\n"
          ]
        }
      ],
      "source": [
        "# Block 1: Access ZIP & Detect Folders (robust)\n",
        "ZIP_PATH = \"/content/FER-2013.zip\"\n",
        "ROOT     = \"/content/FER-2013\"   # extraction root\n",
        "\n",
        "# 1) Unzip once\n",
        "if os.path.exists(ZIP_PATH) and not os.path.isdir(ROOT):\n",
        "    with zipfile.ZipFile(ZIP_PATH, \"r\") as z:\n",
        "        z.extractall(ROOT)\n",
        "    print(\"Unzipped FER-2013 to:\", ROOT)\n",
        "\n",
        "# 2) Find the DEEPEST folder that actually contains splits\n",
        "def find_base(start):\n",
        "    candidates = []\n",
        "    for r, dirs, files in os.walk(start):\n",
        "        if any(d in dirs for d in [\"train\", \"test\", \"PublicTest\", \"PrivateTest\"]):\n",
        "            candidates.append(r)\n",
        "    if not candidates:\n",
        "        return start\n",
        "    return sorted(candidates, key=lambda p: len(p.split(\"/\")))[-1]\n",
        "\n",
        "BASE = find_base(ROOT)\n",
        "print(\"Base folder detected:\", BASE)\n",
        "\n",
        "# 3) Prefer official split names if present\n",
        "TRAIN_DIR_OFF   = os.path.join(BASE, \"train\")\n",
        "PUBLIC_DIR_OFF  = os.path.join(BASE, \"PublicTest\")\n",
        "PRIVATE_DIR_OFF = os.path.join(BASE, \"PrivateTest\")\n",
        "\n",
        "HAS_OFFICIAL = all(os.path.isdir(p) for p in [TRAIN_DIR_OFF, PUBLIC_DIR_OFF, PRIVATE_DIR_OFF])\n",
        "print(\"Official splits found:\", HAS_OFFICIAL)\n",
        "\n",
        "# 4) Fallback (your ZIP has only train/test)\n",
        "TRAIN_SPLIT = os.path.join(BASE, \"train_split\")\n",
        "VAL_SPLIT   = os.path.join(BASE, \"val_split\")\n",
        "TEST_DIR_FALLBACK = os.path.join(BASE, \"test\")\n",
        "\n",
        "if HAS_OFFICIAL:\n",
        "    TRAIN_DIR = TRAIN_DIR_OFF\n",
        "    VAL_DIR   = PUBLIC_DIR_OFF\n",
        "    TEST_DIR  = PRIVATE_DIR_OFF  # FINAL TEST\n",
        "else:\n",
        "    TRAIN_DIR = TRAIN_SPLIT if os.path.isdir(TRAIN_SPLIT) else TRAIN_DIR_OFF\n",
        "    VAL_DIR   = VAL_SPLIT   if os.path.isdir(VAL_SPLIT)   else PUBLIC_DIR_OFF if os.path.isdir(PUBLIC_DIR_OFF) else TRAIN_DIR\n",
        "    TEST_DIR  = TEST_DIR_FALLBACK\n",
        "\n",
        "print(\"TRAIN_DIR:\", TRAIN_DIR)\n",
        "print(\"VAL_DIR:  \", VAL_DIR)\n",
        "print(\"TEST_DIR: \", TEST_DIR)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYTfVSGpIeZC"
      },
      "source": [
        "**Block 2 — Quick Sanity Check (counts)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gyDyUJbaIi7n",
        "outputId": "459aac43-5b0a-4af8-a989-4675ffae067a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: total=28709, per_class={'angry': 3995, 'disgust': 436, 'fear': 4097, 'happy': 7215, 'neutral': 4965, 'sad': 4830, 'surprise': 3171}\n",
            "PublicTest/Val: total=28709, per_class={'angry': 3995, 'disgust': 436, 'fear': 4097, 'happy': 7215, 'neutral': 4965, 'sad': 4830, 'surprise': 3171}\n",
            "PrivateTest/Final: total=7178, per_class={'angry': 958, 'disgust': 111, 'fear': 1024, 'happy': 1774, 'neutral': 1233, 'sad': 1247, 'surprise': 831}\n"
          ]
        }
      ],
      "source": [
        "# Block 2: Sanity Check: class names and image counts\n",
        "def count_images(root):\n",
        "    total = 0\n",
        "    per_class = {}\n",
        "    if not os.path.isdir(root):\n",
        "        return 0, {}\n",
        "    for cls in sorted(os.listdir(root)):\n",
        "        p = os.path.join(root, cls)\n",
        "        if os.path.isdir(p):\n",
        "            n = len([f for f in os.listdir(p) if f.lower().endswith(('.png','.jpg','.jpeg'))])\n",
        "            per_class[cls] = n\n",
        "            total += n\n",
        "    return total, per_class\n",
        "\n",
        "for name, path in [(\"Train\", TRAIN_DIR), (\"PublicTest/Val\", VAL_DIR), (\"PrivateTest/Final\", TEST_DIR)]:\n",
        "    tot, pc = count_images(path)\n",
        "    print(f\"{name}: total={tot}, per_class={pc}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YrWMK8VzIlTz"
      },
      "source": [
        "**Block 3 — Transforms (CLAHE + augs) & Eval (TenCrop + Fast CenterCrop)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "61N92ODuImjf"
      },
      "outputs": [],
      "source": [
        "# Block 3: Transforms\n",
        "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
        "IMAGENET_STD  = [0.229, 0.224, 0.225]\n",
        "\n",
        "# CLAHE -> returns a PIL RGB image\n",
        "class CLAHE_PIL(object):\n",
        "    def __init__(self, clip=2.0, grid=(8,8)):\n",
        "        self.clip = clip; self.grid = grid\n",
        "    def __call__(self, img: Image.Image):\n",
        "        g = np.array(img.convert(\"L\"))\n",
        "        clahe = cv2.createCLAHE(clipLimit=self.clip, tileGridSize=self.grid)\n",
        "        g = clahe.apply(g)\n",
        "        rgb = cv2.cvtColor(g, cv2.COLOR_GRAY2RGB)\n",
        "        return Image.fromarray(rgb)\n",
        "\n",
        "# Train pipeline: CLAHE + strong augs\n",
        "train_transform = transforms.Compose([\n",
        "    CLAHE_PIL(clip=2.0, grid=(8,8)),\n",
        "    transforms.Resize(56),\n",
        "    transforms.RandomResizedCrop(48, scale=(0.8, 1.2)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD),\n",
        "])\n",
        "\n",
        "# Eval pipeline: TenCrop (TTA)\n",
        "eval_transform = transforms.Compose([\n",
        "    CLAHE_PIL(clip=2.0, grid=(8,8)),\n",
        "    transforms.Resize(56),\n",
        "    transforms.TenCrop(48),\n",
        "    transforms.Lambda(lambda crops: torch.stack([\n",
        "        transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD)(\n",
        "            transforms.ToTensor()(c)\n",
        "        ) for c in crops\n",
        "    ])),\n",
        "])\n",
        "\n",
        "# FAST eval pipeline: single CenterCrop for quick validation\n",
        "eval_transform_fast = transforms.Compose([\n",
        "    CLAHE_PIL(clip=2.0, grid=(8,8)),\n",
        "    transforms.Resize(56),\n",
        "    transforms.CenterCrop(48),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD),\n",
        "])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kQ8RbEBIoLK"
      },
      "source": [
        "**Block 4 — Datasets & Dataloaders (class-map fixed + fast val loader)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqHnBJnkIpRO",
        "outputId": "d9e36cd6-fd99-462a-f4f3-6242440807ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fixed classes: ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n",
            "Train n: 28709 | Val n: 28709 | Test n: 7178\n"
          ]
        }
      ],
      "source": [
        "# Block 4: Datasets & Dataloaders (fixed class mapping + fast val loader)\n",
        "assert os.path.isdir(TRAIN_DIR), f\"Missing TRAIN_DIR: {TRAIN_DIR}\"\n",
        "assert os.path.isdir(TEST_DIR),  f\"Missing TEST_DIR: {TEST_DIR}\"\n",
        "assert os.path.isdir(VAL_DIR),   f\"Missing VAL_DIR: {VAL_DIR}\"\n",
        "\n",
        "train_ds      = datasets.ImageFolder(TRAIN_DIR, transform=train_transform)\n",
        "val_ds        = datasets.ImageFolder(VAL_DIR,   transform=eval_transform)\n",
        "val_ds_fast   = datasets.ImageFolder(VAL_DIR,   transform=eval_transform_fast)\n",
        "test_ds       = datasets.ImageFolder(TEST_DIR,  transform=eval_transform)\n",
        "\n",
        "# ---- Force consistent class mapping using TRAIN classes ----\n",
        "fixed_classes = train_ds.classes\n",
        "fixed_map = {cls: i for i, cls in enumerate(fixed_classes)}\n",
        "\n",
        "def remap_dataset_targets(ds, fixed_map):\n",
        "    local_classes = ds.classes\n",
        "    idx2global = {i: fixed_map[c] for i, c in enumerate(local_classes) if c in fixed_map}\n",
        "\n",
        "    if hasattr(ds, \"samples\"):\n",
        "        new_samples = []\n",
        "        for p, t in ds.samples:\n",
        "            if t in idx2global:\n",
        "                new_samples.append((p, idx2global[t]))\n",
        "        ds.samples = new_samples\n",
        "        ds.targets = [t for _, t in ds.samples]\n",
        "\n",
        "    ds.classes = list(fixed_map.keys())\n",
        "    ds.class_to_idx = dict(fixed_map)\n",
        "    return ds\n",
        "\n",
        "val_ds      = remap_dataset_targets(val_ds, fixed_map)\n",
        "val_ds_fast = remap_dataset_targets(val_ds_fast, fixed_map)\n",
        "test_ds     = remap_dataset_targets(test_ds, fixed_map)\n",
        "\n",
        "print(\"Fixed classes:\", fixed_classes)\n",
        "print(\"Train n:\", len(train_ds), \"| Val n:\", len(val_ds), \"| Test n:\", len(test_ds))\n",
        "\n",
        "# Dataloader helper (tries speed flags and falls back if unsupported)\n",
        "def make_loader(ds, batch_size, shuffle):\n",
        "    try:\n",
        "        return DataLoader(ds, batch_size=batch_size, shuffle=shuffle,\n",
        "                          num_workers=2, pin_memory=True,\n",
        "                          persistent_workers=True, prefetch_factor=4)\n",
        "    except TypeError:\n",
        "        return DataLoader(ds, batch_size=batch_size, shuffle=shuffle,\n",
        "                          num_workers=2, pin_memory=True)\n",
        "\n",
        "BATCH_TRAIN = 64\n",
        "BATCH_EVAL  = 64  # a bit larger since eval is lighter\n",
        "\n",
        "train_loader    = make_loader(train_ds,    BATCH_TRAIN, True)\n",
        "val_loader      = make_loader(val_ds,      BATCH_EVAL,  False)      # TenCrop (5D)\n",
        "val_loader_fast = make_loader(val_ds_fast, BATCH_EVAL,  False)      # CenterCrop (4D)\n",
        "test_loader     = make_loader(test_ds,     BATCH_EVAL,  False)      # TenCrop (5D)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2PiPbCTIrii"
      },
      "source": [
        "**Block 5 — Model (ResNet34) + Loss/Opt/Scheduler**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37kV6yYlIsd2",
        "outputId": "9bdfd3b1-70c0-49be-d691-1dc68fa280a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 83.3M/83.3M [00:00<00:00, 198MB/s]\n",
            "/tmp/ipython-input-2156613188.py:52: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler    = torch.cuda.amp.GradScaler()\n"
          ]
        }
      ],
      "source": [
        "# Block 5: Model + Loss/Opt/Scheduler\n",
        "class EmotionResNet34(nn.Module):\n",
        "    def __init__(self, num_classes=7, dropout=0.5):\n",
        "        super().__init__()\n",
        "        self.backbone = models.resnet34(weights=models.ResNet34_Weights.DEFAULT)\n",
        "        in_features = self.backbone.fc.in_features\n",
        "        self.backbone.fc = nn.Identity()\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.BatchNorm1d(in_features),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(in_features, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(256, num_classes)\n",
        "        )\n",
        "        self._init_weights()\n",
        "    def _init_weights(self):\n",
        "        for m in self.classifier:\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.kaiming_normal_(m.weight)\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "    def forward(self, x):\n",
        "        feat = self.backbone(x)\n",
        "        out  = self.classifier(feat)\n",
        "        return out\n",
        "\n",
        "model = EmotionResNet34().to(device)\n",
        "\n",
        "# Label smoothing loss\n",
        "class LabelSmoothingLoss(nn.Module):\n",
        "    def __init__(self, smoothing=0.1):\n",
        "        super().__init__()\n",
        "        self.smoothing = smoothing\n",
        "        self.confidence = 1.0 - smoothing\n",
        "    def forward(self, pred, target):\n",
        "        log_probs = F.log_softmax(pred, dim=-1)\n",
        "        n = pred.size(1)\n",
        "        true_dist = torch.zeros_like(log_probs)\n",
        "        true_dist.scatter_(1, target.unsqueeze(1), self.confidence)\n",
        "        true_dist += self.smoothing / n\n",
        "        return torch.mean(torch.sum(-true_dist * log_probs, dim=-1))\n",
        "\n",
        "criterion = LabelSmoothingLoss(0.1)\n",
        "optimizer = AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2)\n",
        "scaler    = torch.cuda.amp.GradScaler()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avU0UygpIuDu"
      },
      "source": [
        "**Block 6 — Evaluation Utils (TenCrop + Fast CenterCrop)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "20Cm5uZSIvAG"
      },
      "outputs": [],
      "source": [
        "# Block 6: Evaluation Utils\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate_tencrop(model, loader):\n",
        "    \"\"\"Eval with TenCrop TTA; loader yields 5D tensors: [B, 10, C, H, W].\"\"\"\n",
        "    model.eval()\n",
        "    total, correct = 0, 0\n",
        "    for images, labels in loader:\n",
        "        bs, ncrops, c, h, w = images.size()\n",
        "        images = images.view(-1, c, h, w).to(device)\n",
        "        labels = labels.to(device)\n",
        "        with torch.autocast(device_type='cuda', enabled=(device.type=='cuda')):\n",
        "            logits = model(images)              # [B*10, 7]\n",
        "        logits = logits.view(bs, ncrops, -1).mean(1)  # avg over 10 crops\n",
        "        preds = logits.argmax(1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total   += labels.size(0)\n",
        "    return correct / total\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate_center(model, loader):\n",
        "    \"\"\"Fast eval with single CenterCrop; loader yields 4D tensors: [B, C, H, W].\"\"\"\n",
        "    model.eval()\n",
        "    total, correct = 0, 0\n",
        "    for images, labels in loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        with torch.autocast(device_type='cuda', enabled=(device.type=='cuda')):\n",
        "            logits = model(images)\n",
        "        preds = logits.argmax(1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total   += labels.size(0)\n",
        "    return correct / total\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjn71a_3Iwpy"
      },
      "source": [
        "**Block 7 — Stage-1 Training (freeze) — FAST**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dq5hUjkLIxpY",
        "outputId": "0f059d1a-a181-4321-ec22-88a40d82266d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[S1][1/5] loss=2.1507 | train_acc=0.2137 | val_acc_fast=0.2963\n",
            "   ↳ TenCrop-check: 0.3121\n",
            "   ↳ Saved best Stage-1 weights.\n",
            "[S1][2/5] loss=1.8638 | train_acc=0.2513 | val_acc_fast=0.3049\n",
            "   ↳ TenCrop-check: 0.3061\n",
            "[S1][3/5] loss=1.8221 | train_acc=0.2671 | val_acc_fast=0.3165\n",
            "   ↳ TenCrop-check: 0.3281\n",
            "   ↳ Saved best Stage-1 weights.\n",
            "[S1][4/5] loss=1.8074 | train_acc=0.2770 | val_acc_fast=0.3177\n",
            "   ↳ TenCrop-check: 0.3323\n",
            "   ↳ Saved best Stage-1 weights.\n",
            "[S1][5/5] loss=1.8015 | train_acc=0.2851 | val_acc_fast=0.3229\n",
            "   ↳ TenCrop-check: 0.3418\n",
            "   ↳ Saved best Stage-1 weights.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# Block 7 (FAST): Stage-1 Training (Freeze backbone)\n",
        "for p in model.backbone.parameters():\n",
        "    p.requires_grad = False\n",
        "\n",
        "best_val_acc_tta  = 0.0   # best TenCrop val acc (we save on this)\n",
        "best_val_acc_fast = 0.0   # track fast proxy\n",
        "best_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "EPOCHS_S1, PATIENCE_S1 = 5, 2\n",
        "\n",
        "for epoch in range(EPOCHS_S1):\n",
        "    model.train()\n",
        "    running_loss = 0.0; correct = 0; total = 0\n",
        "\n",
        "    for x, y in train_loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        with torch.autocast(device_type='cuda', enabled=(device.type=='cuda')):\n",
        "            logits = model(x)\n",
        "            loss = criterion(logits, y)\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        running_loss += loss.item() * x.size(0)\n",
        "        correct      += (logits.argmax(1) == y).sum().item()\n",
        "        total        += y.size(0)\n",
        "\n",
        "    scheduler.step()\n",
        "    train_loss = running_loss / total\n",
        "    train_acc  = correct / total\n",
        "\n",
        "    # FAST validation (CenterCrop)\n",
        "    val_acc_fast = evaluate_center(model, val_loader_fast)\n",
        "    print(f\"[S1][{epoch+1}/{EPOCHS_S1}] loss={train_loss:.4f} | train_acc={train_acc:.4f} | val_acc_fast={val_acc_fast:.4f}\")\n",
        "\n",
        "    # If fast validation improved, confirm with TenCrop (expensive)\n",
        "    improved = val_acc_fast > best_val_acc_fast + 1e-6\n",
        "    if improved:\n",
        "        best_val_acc_fast = val_acc_fast\n",
        "        val_acc_tta = evaluate_tencrop(model, val_loader)\n",
        "        print(f\"   ↳ TenCrop-check: {val_acc_tta:.4f}\")\n",
        "        if val_acc_tta > best_val_acc_tta + 1e-6:\n",
        "            best_val_acc_tta = val_acc_tta\n",
        "            best_wts = copy.deepcopy(model.state_dict())\n",
        "            torch.save(best_wts, \"/content/best_fer_model_stage1.pth\")\n",
        "            print(\"   ↳ Saved best Stage-1 weights.\")\n",
        "            PATIENCE_S1 = 2  # reset a bit\n",
        "        else:\n",
        "            PATIENCE_S1 -= 1\n",
        "    else:\n",
        "        PATIENCE_S1 -= 1\n",
        "\n",
        "    if PATIENCE_S1 <= 0:\n",
        "        print(\"   ↳ Early stop Stage-1.\")\n",
        "        break\n",
        "\n",
        "# Load best Stage-1\n",
        "model.load_state_dict(best_wts)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "882HvDngIzvN"
      },
      "source": [
        "**Block 8 — Stage-2 Fine-Tuning (unfreeze layer4 only; discrim LRs) — FAST**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dc-x6icNI0mQ",
        "outputId": "404e9cdb-cfbc-4917-8e8c-cb97e589d239"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[S2][1/12] loss=1.7310 | train_acc=0.3369 | val_acc_fast=0.4164\n",
            "   ↳ TenCrop-check: 0.4531\n",
            "   ↳ Saved best Stage-2 weights.\n",
            "[S2][2/12] loss=1.6559 | train_acc=0.3873 | val_acc_fast=0.4477\n",
            "   ↳ TenCrop-check: 0.4803\n",
            "   ↳ Saved best Stage-2 weights.\n",
            "[S2][3/12] loss=1.6170 | train_acc=0.4132 | val_acc_fast=0.4647\n",
            "   ↳ TenCrop-check: 0.5003\n",
            "   ↳ Saved best Stage-2 weights.\n",
            "[S2][4/12] loss=1.5907 | train_acc=0.4291 | val_acc_fast=0.4818\n",
            "   ↳ TenCrop-check: 0.5179\n",
            "   ↳ Saved best Stage-2 weights.\n",
            "[S2][5/12] loss=1.5736 | train_acc=0.4325 | val_acc_fast=0.4876\n",
            "   ↳ TenCrop-check: 0.5186\n",
            "   ↳ Saved best Stage-2 weights.\n",
            "[S2][6/12] loss=1.5562 | train_acc=0.4422 | val_acc_fast=0.4958\n",
            "   ↳ TenCrop-check: 0.5342\n",
            "   ↳ Saved best Stage-2 weights.\n",
            "[S2][7/12] loss=1.5448 | train_acc=0.4507 | val_acc_fast=0.4979\n",
            "   ↳ TenCrop-check: 0.5368\n",
            "   ↳ Saved best Stage-2 weights.\n",
            "[S2][8/12] loss=1.5369 | train_acc=0.4548 | val_acc_fast=0.4989\n",
            "   ↳ TenCrop-check: 0.5386\n",
            "   ↳ Saved best Stage-2 weights.\n",
            "[S2][9/12] loss=1.5554 | train_acc=0.4492 | val_acc_fast=0.4929\n",
            "[S2][10/12] loss=1.5470 | train_acc=0.4480 | val_acc_fast=0.4999\n",
            "   ↳ TenCrop-check: 0.5386\n",
            "[S2][11/12] loss=1.5383 | train_acc=0.4548 | val_acc_fast=0.5060\n",
            "   ↳ TenCrop-check: 0.5368\n",
            "   ↳ Early stop Stage-2.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# Block 8 (FAST): Stage-2 Fine-Tune (unfreeze only layer4; discriminative LRs)\n",
        "for name, p in model.backbone.named_parameters():\n",
        "    p.requires_grad = (\"layer4\" in name)  # only last block learns\n",
        "\n",
        "# Two param groups: lower LR for backbone layer4, higher LR for head\n",
        "head_params = list(model.classifier.parameters())\n",
        "l4_params   = [p for n,p in model.backbone.named_parameters() if \"layer4\" in n]\n",
        "optimizer = AdamW([\n",
        "    {\"params\": l4_params,   \"lr\": 1e-4},\n",
        "    {\"params\": head_params, \"lr\": 3e-4},\n",
        "], weight_decay=1e-4)\n",
        "\n",
        "scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=8, T_mult=2)\n",
        "\n",
        "best_val_acc_ft_tta  = best_val_acc_tta\n",
        "best_val_acc_ft_fast = best_val_acc_fast\n",
        "best_wts_ft = copy.deepcopy(model.state_dict())\n",
        "\n",
        "EPOCHS_S2, PATIENCE_S2 = 12, 3\n",
        "\n",
        "for epoch in range(EPOCHS_S2):\n",
        "    model.train()\n",
        "    running_loss = 0.0; correct = 0; total = 0\n",
        "\n",
        "    for x, y in train_loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        with torch.autocast(device_type='cuda', enabled=(device.type=='cuda')):\n",
        "            logits = model(x)\n",
        "            loss = criterion(logits, y)\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        running_loss += loss.item() * x.size(0)\n",
        "        correct      += (logits.argmax(1) == y).sum().item()\n",
        "        total        += y.size(0)\n",
        "\n",
        "    scheduler.step()\n",
        "    train_loss = running_loss / total\n",
        "    train_acc  = correct / total\n",
        "\n",
        "    val_acc_fast = evaluate_center(model, val_loader_fast)\n",
        "    print(f\"[S2][{epoch+1}/{EPOCHS_S2}] loss={train_loss:.4f} | train_acc={train_acc:.4f} | val_acc_fast={val_acc_fast:.4f}\")\n",
        "\n",
        "    improved = val_acc_fast > best_val_acc_ft_fast + 1e-6\n",
        "    if improved:\n",
        "        best_val_acc_ft_fast = val_acc_fast\n",
        "        val_acc_tta = evaluate_tencrop(model, val_loader)\n",
        "        print(f\"   ↳ TenCrop-check: {val_acc_tta:.4f}\")\n",
        "        if val_acc_tta > best_val_acc_ft_tta + 1e-6:\n",
        "            best_val_acc_ft_tta = val_acc_tta\n",
        "            best_wts_ft = copy.deepcopy(model.state_dict())\n",
        "            torch.save(best_wts_ft, \"/content/best_fer_model_finetuned.pth\")\n",
        "            print(\"   ↳ Saved best Stage-2 weights.\")\n",
        "            PATIENCE_S2 = 3\n",
        "        else:\n",
        "            PATIENCE_S2 -= 1\n",
        "    else:\n",
        "        PATIENCE_S2 -= 1\n",
        "\n",
        "    if PATIENCE_S2 <= 0:\n",
        "        print(\"   ↳ Early stop Stage-2.\")\n",
        "        break\n",
        "\n",
        "# Load best fine-tuned model\n",
        "model.load_state_dict(best_wts_ft)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qu9OjdcDI2tn"
      },
      "source": [
        "**Block 9 — FINAL Test (TenCrop TTA) on test**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "li42U5ZKI3mG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d749779-0129-4958-e4f1-a32ecfe6c267"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded best checkpoint: /content/best_fer_model_finetuned.pth\n",
            "\n",
            " FINAL TEST ACCURACY (TenCrop TTA) on test/: 52.54%\n"
          ]
        }
      ],
      "source": [
        "# Block 9: FINAL Test (PrivateTest if available)\n",
        "final_ckpt = \"/content/best_fer_model_finetuned.pth\"\n",
        "if not os.path.exists(final_ckpt):\n",
        "    final_ckpt = \"/content/best_fer_model_stage1.pth\"\n",
        "\n",
        "if os.path.exists(final_ckpt):\n",
        "    model.load_state_dict(torch.load(final_ckpt, map_location=device))\n",
        "    print(\"Loaded best checkpoint:\", final_ckpt)\n",
        "else:\n",
        "    print(\"No saved checkpoint found; using in-memory weights.\")\n",
        "\n",
        "final_test_acc = evaluate_tencrop(model, test_loader)\n",
        "split_name = \"PrivateTest\" if os.path.basename(TEST_DIR).lower() == \"privatetest\" else \"test/\"\n",
        "print(f\"\\n FINAL TEST ACCURACY (TenCrop TTA) on {split_name}: {final_test_acc*100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DaWJ_Fo0I5VX"
      },
      "source": [
        "**Block 10 — Confusion Matrix on Final Test**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "UoTDuFIFI6h_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f84919e-676a-4cd6-a62a-6db118f5618b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            " [[ 396    0   32  155  131  214   30]\n",
            " [  57    0    4   17    6   22    5]\n",
            " [ 152    0  125  136  174  304  133]\n",
            " [  54    0   16 1466   86  122   30]\n",
            " [  77    0   36  220  639  220   41]\n",
            " [ 152    0   59  181  232  599   24]\n",
            " [  43    0   51   77   78   36  546]]\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.43      0.41      0.42       958\n",
            "     disgust       0.00      0.00      0.00       111\n",
            "        fear       0.39      0.12      0.19      1024\n",
            "       happy       0.65      0.83      0.73      1774\n",
            "     neutral       0.47      0.52      0.50      1233\n",
            "         sad       0.39      0.48      0.43      1247\n",
            "    surprise       0.67      0.66      0.67       831\n",
            "\n",
            "    accuracy                           0.53      7178\n",
            "   macro avg       0.43      0.43      0.42      7178\n",
            "weighted avg       0.50      0.53      0.50      7178\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "# Block 10: Confusion Matrix (optional)\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "@torch.no_grad()\n",
        "def predict_all(model, loader):\n",
        "    model.eval(); ys, yh = [], []\n",
        "    for images, labels in loader:\n",
        "        bs, ncrops, c, h, w = images.size()\n",
        "        images = images.view(-1, c, h, w).to(device)\n",
        "        labels = labels.to(device)\n",
        "        with torch.autocast(device_type='cuda', enabled=(device.type=='cuda')):\n",
        "            logits = model(images)\n",
        "        logits = logits.view(bs, ncrops, -1).mean(1)\n",
        "        preds = logits.argmax(1)\n",
        "        ys.append(labels.cpu().numpy())\n",
        "        yh.append(preds.cpu().numpy())\n",
        "    return np.concatenate(ys), np.concatenate(yh)\n",
        "\n",
        "y_true, y_pred = predict_all(model, test_loader)\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_true, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_true, y_pred, target_names=fixed_classes))\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyNmGLl93n2SKWeqeHgSVO1r",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}