{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "runtime_attributes": {
        "runtime_version": "2025.10"
      },
      "authorship_tag": "ABX9TyPh72DR7e7pgX7GLV7cYPRQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rafi076/RTFER/blob/main/Copy_of_ER2013_Ensemble_EffNetB3_ResNet50_Xception.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "15241-8pLfkB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bca0512-4543-4a47-88d4-ba6dd770463b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'fer2013' dataset.\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "path = kagglehub.dataset_download(\"msambare/fer2013\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "print(\"Dataset root path:\")\n",
        "print(path)\n",
        "\n",
        "print(\"\\nContents of dataset root:\")\n",
        "print(os.listdir(path))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YAT63HF5NpBA",
        "outputId": "3c664257-f1b8-4460-f957-d39a914ff1cb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset root path:\n",
            "/kaggle/input/fer2013\n",
            "\n",
            "Contents of dataset root:\n",
            "['test', 'train']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Environment & Library Setup**"
      ],
      "metadata": {
        "id": "TdW0u2ekPMfE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Core deep learning\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models, optimizers, callbacks\n",
        "\n",
        "# Numerical & data handling\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Image processing\n",
        "import cv2\n",
        "from skimage import exposure, filters\n",
        "\n",
        "# Machine learning utilities\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    confusion_matrix,\n",
        "    classification_report,\n",
        "    roc_auc_score\n",
        ")\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# System & utility\n",
        "import os\n",
        "import random\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Environment check\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "print(\"GPU Available:\", tf.config.list_physical_devices('GPU'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0R2xzOQ-Ojkt",
        "outputId": "33f84588-af95-4035-cb48-88044b4de856"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.19.0\n",
            "GPU Available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "------"
      ],
      "metadata": {
        "id": "NJNZ6W7nYfAl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Preprocessing Pipeline**"
      ],
      "metadata": {
        "id": "5-wsnfffRV_4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports for preprocessing\n",
        "from tensorflow.keras.applications import (\n",
        "    resnet50,\n",
        "    xception,\n",
        "    efficientnet\n",
        ")\n"
      ],
      "metadata": {
        "id": "I7hA81t3RZZR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.1: *Face-Aware Center Alignment (lightweight & safe)*\n",
        "\n",
        "FER-2013 faces are mostly centered, so we use center cropping + landmark-free alignment\n",
        "(this avoids unstable landmark detectors on low-res faces)."
      ],
      "metadata": {
        "id": "JskmJwhvRwm0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def face_aware_center_align(img, crop_ratio=0.9):\n",
        "    \"\"\"\n",
        "    Light face-aware center alignment using center crop.\n",
        "    Safe for FER-2013.\n",
        "    \"\"\"\n",
        "    h, w = img.shape[:2]\n",
        "    crop_h, crop_w = int(h * crop_ratio), int(w * crop_ratio)\n",
        "\n",
        "    start_x = (w - crop_w) // 2\n",
        "    start_y = (h - crop_h) // 2\n",
        "\n",
        "    return img[start_y:start_y + crop_h, start_x:start_x + crop_w]\n"
      ],
      "metadata": {
        "id": "HK4DXr3fR2Qp"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.2: *CLAHE (Contrast Enhancement)*"
      ],
      "metadata": {
        "id": "4U9eyGxfSBH8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_clahe(gray_img):\n",
        "    clahe = cv2.createCLAHE(\n",
        "        clipLimit=2.0,\n",
        "        tileGridSize=(8, 8)\n",
        "    )\n",
        "    return clahe.apply(gray_img)\n"
      ],
      "metadata": {
        "id": "V1gqy0yTSC5p"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.2.1 ***Gamma Correction*** (This balances the lighting before you enhance contrast)  &    ***NLM Denoising*** (Upgrade from Gaussian. Gaussian blur can \"muddy\" the edges of the lips. Non-Local Means (NLM) denoising is superior because it removes grain while keeping edges razor-sharp)"
      ],
      "metadata": {
        "id": "T1TRGPmCVlos"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_gamma_correction(img, gamma=1.1):\n",
        "    \"\"\"Normalizes global illumination before contrast enhancement.\"\"\"\n",
        "    invGamma = 1.0 / gamma\n",
        "    table = np.array([((i / 255.0) ** invGamma) * 255\n",
        "                      for i in np.arange(0, 256)]).astype(\"uint8\")\n",
        "    return cv2.LUT(img, table)\n",
        "\n",
        "def apply_denoising(img):\n",
        "    \"\"\"Removes digital grain while preserving sharp edges of lips/eyes.\"\"\"\n",
        "    # fastNlMeans is superior to Gaussian for keeping micro-expression edges\n",
        "    return cv2.fastNlMeansDenoising(img, None, h=3, templateWindowSize=7, searchWindowSize=21)"
      ],
      "metadata": {
        "id": "qPrPck7wWJdg"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.3: *Light Gaussian Smoothing*"
      ],
      "metadata": {
        "id": "PXXaHo4mSPuh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gaussian_smoothing(img):\n",
        "    return cv2.GaussianBlur(img, (3, 3), 0)\n"
      ],
      "metadata": {
        "id": "-Afa5yDPST1I"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.4: *Grayscale → RGB Conversion*"
      ],
      "metadata": {
        "id": "_8djAJ23SYB8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gray_to_rgb(gray_img):\n",
        "    return cv2.cvtColor(gray_img, cv2.COLOR_GRAY2RGB)\n"
      ],
      "metadata": {
        "id": "-C601yYgSVVu"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.5: *Model-Specific Resize*"
      ],
      "metadata": {
        "id": "SJFmVFjaSlUU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def resize_for_model(img, model_name):\n",
        "    if model_name == \"resnet50\":\n",
        "        return cv2.resize(img, (224, 224))\n",
        "    elif model_name == \"xception\":\n",
        "        return cv2.resize(img, (299, 299))\n",
        "    elif model_name == \"efficientnetb3\":\n",
        "        return cv2.resize(img, (300, 300))\n",
        "    else:\n",
        "        raise ValueError(\"Unknown model name\")\n"
      ],
      "metadata": {
        "id": "z0oFtNIfSccd"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.6: *Model-Specific Normalization*"
      ],
      "metadata": {
        "id": "848CdvYISsGM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_for_model(img, model_name):\n",
        "    img = img.astype(np.float32)\n",
        "\n",
        "    if model_name == \"resnet50\":\n",
        "        return resnet50.preprocess_input(img)\n",
        "    elif model_name == \"xception\":\n",
        "        return xception.preprocess_input(img)\n",
        "    elif model_name == \"efficientnetb3\":\n",
        "        return efficientnet.preprocess_input(img)\n",
        "    else:\n",
        "        raise ValueError(\"Unknown model name\")\n"
      ],
      "metadata": {
        "id": "nWgSgTuzSpou"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.7: *FULL Preprocessing Function*"
      ],
      "metadata": {
        "id": "LKzmS1i8S0Eg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_image(image_path, model_name):\n",
        "    # 1. Read image (FER-2013 grayscale)\n",
        "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    # 2. Face-aware alignment (Your crop)\n",
        "    img = face_aware_center_align(img)\n",
        "\n",
        "    # 3. [NEW] Gamma Correction (Balance lighting FIRST)\n",
        "    img = apply_gamma_correction(img, gamma=1.2)\n",
        "\n",
        "    # 4. [NEW] Denoising (Clean grain BEFORE sharpening)\n",
        "    img = apply_denoising(img)\n",
        "\n",
        "    # 5. CLAHE (Contrast Enhancement - now works on clean pixels)\n",
        "    img = apply_clahe(img)\n",
        "\n",
        "    # 6. Gray → RGB (Convert for ImageNet weights)\n",
        "    img = gray_to_rgb(img)\n",
        "\n",
        "    # 7. Resize (Model-specific)\n",
        "    target_size = (224, 224)\n",
        "    if model_name == \"xception\": target_size = (299, 299)\n",
        "    if model_name == \"efficientnetb3\": target_size = (300, 300)\n",
        "\n",
        "    img = cv2.resize(img, target_size, interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "    # 8. Model-specific normalization\n",
        "    img = preprocess_for_model(img, model_name)\n",
        "\n",
        "    return img"
      ],
      "metadata": {
        "id": "dIkxxC00Swoy"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "------------------------\n"
      ],
      "metadata": {
        "id": "ZN8mLEnPYY8R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. **Dataset Splitting**"
      ],
      "metadata": {
        "id": "siVajLBqYhiA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.1: *Define dataset paths*"
      ],
      "metadata": {
        "id": "rEPgmC8KYy9a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_ROOT = path  # /kaggle/input/fer2013\n",
        "TRAIN_DIR = os.path.join(DATASET_ROOT, \"train\")\n",
        "TEST_DIR  = os.path.join(DATASET_ROOT, \"test\")\n",
        "\n",
        "print(\"Train dir:\", TRAIN_DIR)\n",
        "print(\"Test dir :\", TEST_DIR)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aeRGPG5uYZsA",
        "outputId": "effb3868-b5fd-4adc-f0de-7f80bacda8d2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dir: /kaggle/input/fer2013/train\n",
            "Test dir : /kaggle/input/fer2013/test\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.2: *Read all training image paths & labels*"
      ],
      "metadata": {
        "id": "Fp0bSXR9YZU4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_image_paths_and_labels(root_dir):\n",
        "    image_paths = []\n",
        "    labels = []\n",
        "\n",
        "    for label_name in sorted(os.listdir(root_dir)):\n",
        "        label_path = os.path.join(root_dir, label_name)\n",
        "        if not os.path.isdir(label_path):\n",
        "            continue\n",
        "        for img_name in os.listdir(label_path):\n",
        "            image_paths.append(os.path.join(label_path, img_name))\n",
        "            labels.append(label_name)\n",
        "    return image_paths, labels\n",
        "\n",
        "train_image_paths, train_labels = load_image_paths_and_labels(TRAIN_DIR)\n",
        "test_image_paths, test_labels = load_image_paths_and_labels(TEST_DIR)\n",
        "\n",
        "print(\"Total training images:\", len(train_image_paths))\n",
        "print(\"Total test images    :\", len(test_image_paths))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hiHVTOswYV9h",
        "outputId": "2cda1014-865f-49b7-f9d5-092c8d0fee09"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total training images: 28709\n",
            "Total test images    : 7178\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.3: *Encode labels (string → integer*"
      ],
      "metadata": {
        "id": "QEB3vGV8ZEhs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hard-coding classes ensures indices NEVER change between splits\n",
        "classes = ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.fit(classes)  # Fit on known labels, NOT folder names\n",
        "\n",
        "train_labels_encoded = label_encoder.transform(train_labels)\n",
        "test_labels_encoded  = label_encoder.transform(test_labels)\n",
        "\n",
        "NUM_CLASSES = len(label_encoder.classes_)\n",
        "print(\"Classes:\", label_encoder.classes_)\n",
        "print(\"Number of classes:\", NUM_CLASSES)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBgZbZV7Z77R",
        "outputId": "d9fb2ac1-ddda-48b2-9b0d-c241c57bf872"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes: ['angry' 'disgust' 'fear' 'happy' 'neutral' 'sad' 'surprise']\n",
            "Number of classes: 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.4: Split Train → Train (70%) + Validation (15%)\n",
        "\n",
        "We do:\n",
        "\n",
        "85% → temp (train+val)\n",
        "\n",
        "15% → validation\n",
        "\n",
        "Then split temp into 70% train *italicized text*"
      ],
      "metadata": {
        "id": "IwoV4Q8MaBmx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Split off 15% for Validation\n",
        "X_temp, X_val, y_temp, y_val = train_test_split(\n",
        "    train_image_paths,\n",
        "    train_labels_encoded,\n",
        "    test_size=0.15,\n",
        "    stratify=train_labels_encoded,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Step 2: Further split X_temp to get ~70% final training\n",
        "X_train, X_unused, y_train, y_unused = train_test_split(\n",
        "    X_temp,\n",
        "    y_temp,\n",
        "    test_size=0.1765,  # makes final train ≈70%\n",
        "    stratify=y_temp,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(\"Train size     :\", len(X_train))\n",
        "print(\"Validation size:\", len(X_val))\n",
        "print(\"Test size      :\", len(test_image_paths))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oc4Fps6yaHMh",
        "outputId": "42c5199a-1a78-49fe-ba64-ea2c21b71e8a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size     : 20095\n",
            "Validation size: 4307\n",
            "Test size      : 7178\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.5: *Load TEST set*"
      ],
      "metadata": {
        "id": "mo8SdD_4aexM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unique, counts = np.unique(y_train, return_counts=True)\n",
        "print(\"Class distribution in Final Train:\", dict(zip(label_encoder.classes_, counts)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zjm6X4ifaj8h",
        "outputId": "a0f5faeb-a9b6-4701-bf91-653ef59d2462"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class distribution in Final Train: {np.str_('angry'): np.int64(2797), np.str_('disgust'): np.int64(306), np.str_('fear'): np.int64(2867), np.str_('happy'): np.int64(5051), np.str_('neutral'): np.int64(3475), np.str_('sad'): np.int64(3380), np.str_('surprise'): np.int64(2219)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "unique, counts = np.unique(y_train, return_counts=True)\n",
        "class_names = label_encoder.classes_\n",
        "\n",
        "plt.figure()\n",
        "plt.bar(class_names, counts)\n",
        "plt.xlabel(\"Emotion Classes\")\n",
        "plt.ylabel(\"Number of Samples\")\n",
        "plt.title(\"Class Distribution in Final Training Set\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "NmwAchPuzQ-T",
        "outputId": "115144d9-fb68-46b5-8d80-712fe9a3a22c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "------"
      ],
      "metadata": {
        "id": "hnYGSzEqapys"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Label Preparation**\n"
      ],
      "metadata": {
        "id": "946VXBl52Rns"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "  4.1. *Label Preparation*  "
      ],
      "metadata": {
        "id": "-t0uTBaW2fOQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# One-Hot Encoding (Train / Validation / Test)\n",
        "y_train_oh = to_categorical(y_train, num_classes=NUM_CLASSES)\n",
        "y_val_oh = to_categorical(y_val, num_classes=NUM_CLASSES)\n",
        "y_test_oh = to_categorical(test_labels_encoded, num_classes=NUM_CLASSES)\n",
        "\n",
        "print(\"One-hot label shapes:\")\n",
        "print(\"Train:\", y_train_oh.shape)\n",
        "print(\"Val  :\", y_val_oh.shape)\n",
        "print(\"Test :\", y_test_oh.shape)\n"
      ],
      "metadata": {
        "id": "SrImxMXtaljW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "793bb395-56a7-4bb5-a0ca-e5b52d3f205f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "One-hot label shapes:\n",
            "Train: (20095, 7)\n",
            "Val  : (4307, 7)\n",
            "Test : (7178, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " 4.2. *Class Weighting (TRAIN ONLY)*"
      ],
      "metadata": {
        "id": "FYK-C2vO2p7u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.utils import class_weight\n",
        "import numpy as np\n",
        "\n",
        "# Compute class weights using TRAIN labels only (no leakage)\n",
        "class_weights = class_weight.compute_class_weight(\n",
        "   class_weight='balanced',\n",
        "    classes=np.unique(y_train),\n",
        "    y=y_train\n",
        ")\n",
        "\n",
        "# Convert to dictionary format required by Keras\n",
        "class_weight_dict = {\n",
        "    cls: weight for cls, weight in zip(np.unique(y_train), class_weights)\n",
        "}\n",
        "\n",
        "print(\"\\nClass Weights (Training Set):\")\n",
        "for k, v in class_weight_dict.items():\n",
        "    print(f\"{label_encoder.classes_[k]}: {v:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7aliOTUE2tWe",
        "outputId": "33cc5dca-8a24-4cd8-d436-7f1c5870d7cb"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Class Weights (Training Set):\n",
            "angry: 1.03\n",
            "disgust: 9.38\n",
            "fear: 1.00\n",
            "happy: 0.57\n",
            "neutral: 0.83\n",
            "sad: 0.85\n",
            "surprise: 1.29\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "----"
      ],
      "metadata": {
        "id": "T_gY6Ff93U2U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. Data Augmentation (Ensemble-Ready)**"
      ],
      "metadata": {
        "id": "HMK6QedW4uqY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*5.1*"
      ],
      "metadata": {
        "id": "qFwKCGtt7cDc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# 1. Training Augmentation (applied AFTER custom preprocessing)\n",
        "train_datagen = ImageDataGenerator(\n",
        "    horizontal_flip=True,\n",
        "    rotation_range=15,\n",
        "    zoom_range=0.15,\n",
        "    brightness_range=[0.85, 1.15],\n",
        "    fill_mode='nearest'  # Prevents black borders after rotation\n",
        ")\n",
        "\n",
        "# 2. Validation & Test (STRICTLY no augmentation)\n",
        "val_test_datagen = ImageDataGenerator()\n",
        "\n",
        "print(\"Data Augmentation Configured.\")\n",
        "print(\"Must be used with a custom data loader to apply 9-step preprocessing first.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TE1d3fN63Vb2",
        "outputId": "085d42eb-3611-4ec0-a939-2c5b0c11741b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Augmentation Configured.\n",
            "Must be used with a custom data loader to apply 9-step preprocessing first.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*5.2*"
      ],
      "metadata": {
        "id": "QAcT1SLC7eew"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# FINAL Data Augmentation (SOTA Version)\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# This is the 'complete' config for 86%+\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rotation_range=15,            # Handle natural head tilts\n",
        "    width_shift_range=0.1,        # Handle faces not perfectly centered\n",
        "    height_shift_range=0.1,       # Handle faces not perfectly centered\n",
        "    shear_range=0.05,             # Very slight shear (don't overdo it!)\n",
        "    zoom_range=0.15,              # Simulates different distances from camera\n",
        "    horizontal_flip=True,         # Emotions are symmetrical\n",
        "    brightness_range=[0.8, 1.2],  # Handle varying lighting/flash\n",
        "    fill_mode='reflect'           # 'reflect' looks more natural than 'nearest' for skin\n",
        ")\n",
        "\n",
        "# Validation/Test: ABSOLUTELY NO augmentation here\n",
        "val_test_datagen = ImageDataGenerator()\n",
        "\n",
        "print(\"Data Augmentation configuration finalized.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "996cts7I6ade",
        "outputId": "f7210a99-3806-44f9-84a2-b37ddc7453eb"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Augmentation configuration finalized.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "------\n"
      ],
      "metadata": {
        "id": "vN1uIrx68vB8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. **Custom Data Loader**"
      ],
      "metadata": {
        "id": "f9HaxQyF8wy8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*6.1: IMAGE LOADING + PREPROCESSING*"
      ],
      "metadata": {
        "id": "ly7BIGT68420"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import Sequence\n",
        "\n",
        "# IMAGE LOADING + PREPROCESSING\n",
        "\n",
        "def load_and_preprocess_image(img_path, target_size):\n",
        "    \"\"\"\n",
        "    Applies the FULL 9-step preprocessing pipeline.\n",
        "    CRITICAL: Signal cleaning happens BEFORE resizing.\n",
        "    \"\"\"\n",
        "    # 1. Read image (FER-2013 is 48x48 grayscale)\n",
        "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "    if img is None:\n",
        "        raise ValueError(f\"Failed to load image: {img_path}\")\n",
        "\n",
        "    # 2. Gamma Correction (Balance lighting on original pixels)\n",
        "    img = apply_gamma_correction(img, gamma=1.1)\n",
        "\n",
        "    # 3. NLM Denoising (Clean grain on original pixels)\n",
        "    img = apply_denoising(img)\n",
        "\n",
        "    # 4. CLAHE (Enhance expressions)\n",
        "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
        "    img = clahe.apply(img)\n",
        "\n",
        "    # 5. HIGH-QUALITY UPSCALING (Using INTER_CUBIC)\n",
        "    # This is key for 86%+. Bicubic creates much smoother edges than standard resize.\n",
        "    img = cv2.resize(img, target_size, interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "    # 6. Normalize to [0, 1]\n",
        "    img = img.astype(\"float32\") / 255.0\n",
        "\n",
        "    # 7. Convert grayscale → RGB (Required for ImageNet backbones)\n",
        "    img = np.stack([img, img, img], axis=-1)\n",
        "\n",
        "    return img"
      ],
      "metadata": {
        "id": "XFxAh2CY8vyg"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*6.2: CUSTOM DATA GENERATOR CLASS*"
      ],
      "metadata": {
        "id": "hYmRvQkJ9FSU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FERDataGenerator(Sequence):\n",
        "    def __init__(\n",
        "        self,\n",
        "        image_paths,\n",
        "        labels,\n",
        "        batch_size,\n",
        "        img_size,\n",
        "        datagen=None,\n",
        "        shuffle=True\n",
        "    ):\n",
        "        self.image_paths = image_paths\n",
        "        self.labels = labels\n",
        "        self.batch_size = batch_size\n",
        "        self.img_size = img_size\n",
        "        self.datagen = datagen\n",
        "        self.shuffle = shuffle\n",
        "        self.indices = np.arange(len(self.image_paths))\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.image_paths) / self.batch_size))\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indices)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Create batch indices\n",
        "        batch_indices = self.indices[idx * self.batch_size : (idx + 1) * self.batch_size]\n",
        "\n",
        "        batch_images = []\n",
        "        batch_labels = []\n",
        "\n",
        "        for i in batch_indices:\n",
        "            # Apply SOTA Preprocessing\n",
        "            img = load_and_preprocess_image(\n",
        "                self.image_paths[i],\n",
        "                target_size=self.img_size\n",
        "            )\n",
        "\n",
        "            # Apply Data Augmentation (ONLY if datagen is provided for training)\n",
        "            if self.datagen is not None:\n",
        "                img = self.datagen.random_transform(img)\n",
        "\n",
        "            batch_images.append(img)\n",
        "            batch_labels.append(self.labels[i])\n",
        "\n",
        "        return np.array(batch_images), np.array(batch_labels)\n",
        "\n",
        "print(\"Custom Data Loader (SOTA) is ready.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-MtIQt39H5-",
        "outputId": "02fb5bc0-27de-4a56-fb01-0898a4e5ca48"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Custom Data Loader (SOTA) is ready.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generator Instances"
      ],
      "metadata": {
        "id": "w00efz219Qsw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Define Model-Specific Target Sizes\n",
        "SIZE_RESNET   = (224, 224)\n",
        "SIZE_XCEPTION = (299, 299)\n",
        "SIZE_EFFNET   = (300, 300)\n",
        "BATCH_SIZE    = 32\n",
        "\n",
        "# --- EFFICIENTNET-B3 GENERATORS ---\n",
        "train_gen_eff = FERDataGenerator(X_train, y_train_oh, batch_size=BATCH_SIZE,\n",
        "                                 img_size=SIZE_EFFNET, datagen=train_datagen)\n",
        "val_gen_eff   = FERDataGenerator(X_val, y_val_oh, batch_size=BATCH_SIZE,\n",
        "                                 img_size=SIZE_EFFNET, datagen=None, shuffle=False)\n",
        "\n",
        "# --- RESNET50 GENERATORS ---\n",
        "train_gen_res = FERDataGenerator(X_train, y_train_oh, batch_size=BATCH_SIZE,\n",
        "                                 img_size=SIZE_RESNET, datagen=train_datagen)\n",
        "val_gen_res   = FERDataGenerator(X_val, y_val_oh, batch_size=BATCH_SIZE,\n",
        "                                 img_size=SIZE_RESNET, datagen=None, shuffle=False)\n",
        "\n",
        "# --- XCEPTION GENERATORS ---\n",
        "train_gen_xcp = FERDataGenerator(X_train, y_train_oh, batch_size=BATCH_SIZE,\n",
        "                                 img_size=SIZE_XCEPTION, datagen=train_datagen)\n",
        "val_gen_xcp   = FERDataGenerator(X_val, y_val_oh, batch_size=BATCH_SIZE,\n",
        "                                 img_size=SIZE_XCEPTION, datagen=None, shuffle=False)\n",
        "\n",
        "# --- TEST GENERATORS (Use for final evaluation) ---\n",
        "test_gen_eff = FERDataGenerator(test_image_paths, y_test_oh, batch_size=BATCH_SIZE,\n",
        "                                img_size=SIZE_EFFNET, datagen=None, shuffle=False)\n",
        "test_gen_res = FERDataGenerator(test_image_paths, y_test_oh, batch_size=BATCH_SIZE,\n",
        "                                img_size=SIZE_RESNET, datagen=None, shuffle=False)\n",
        "test_gen_xcp = FERDataGenerator(test_image_paths, y_test_oh, batch_size=BATCH_SIZE,\n",
        "                                img_size=SIZE_XCEPTION, datagen=None, shuffle=False)\n",
        "\n",
        "print(\" All Ensemble Generators (EffNet, ResNet, Xception) initialized.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sP1PttEA9RWU",
        "outputId": "ec4cb7a5-6cfa-477d-e4bb-12f388b95253"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " All Ensemble Generators (EffNet, ResNet, Xception) initialized.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n"
      ],
      "metadata": {
        "id": "4SBMZXd4X-T6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7.  **Train CNN Models ONE BY ONE**"
      ],
      "metadata": {
        "id": "8zDlXfhiX_4b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Model Training: ResNet50 / Xception / EfficientNet-B3\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import ResNet50, Xception, EfficientNetB3\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "import gc"
      ],
      "metadata": {
        "id": "laLN_nLcYSId"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*7.1. Common Callbacks*"
      ],
      "metadata": {
        "id": "gpC06KEPYX_v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_callbacks(model_name):\n",
        "    early_stop = EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True, verbose=1)\n",
        "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=4, min_lr=1e-7, verbose=1)\n",
        "    checkpoint = ModelCheckpoint(f\"{model_name}_best.h5\", monitor='val_accuracy', save_best_only=True, mode='max', verbose=1)\n",
        "    return [early_stop, reduce_lr, checkpoint]"
      ],
      "metadata": {
        "id": "440fYC91Ycc6"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*7.2. Model Builder Function*"
      ],
      "metadata": {
        "id": "rWv9Si_NYjut"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(base_model_name, input_shape, num_classes, dropout_rate=0.5):\n",
        "    if base_model_name == \"ResNet50\":\n",
        "        base_model = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "    elif base_model_name == \"Xception\":\n",
        "        base_model = Xception(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "    elif base_model_name == \"EffNetB3\":\n",
        "        base_model = EfficientNetB3(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "\n",
        "    # Phase 1: Freeze backbone\n",
        "    base_model.trainable = False\n",
        "\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(dropout_rate)(x)\n",
        "    outputs = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs=base_model.input, outputs=outputs)\n",
        "    return model, base_model"
      ],
      "metadata": {
        "id": "Vo6_65qiYnIo"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*7.3. TRAINING LOOP (Execute one by one for RAM safety)*"
      ],
      "metadata": {
        "id": "iKlRnlvCYvoS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. RESNET50 ---\n",
        "print(\"\\n--- Training ResNet50 ---\")\n",
        "res_model, res_base = build_model(\"ResNet50\", (224, 224, 3), NUM_CLASSES)\n",
        "res_model.compile(optimizer=Adam(1e-3), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Phase 1: Frozen Backbone\n",
        "res_model.fit(train_gen_res, validation_data=val_gen_res, epochs=20,\n",
        "              class_weight=class_weight_dict, callbacks=get_callbacks(\"ResNet50_P1\"))\n",
        "\n",
        "# Phase 2: Fine-tuning\n",
        "res_base.trainable = True\n",
        "for layer in res_base.layers[:140]: layer.trainable = False # Freeze first 140 layers\n",
        "res_model.compile(optimizer=Adam(1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "res_model.fit(train_gen_res, validation_data=val_gen_res, epochs=30,\n",
        "              class_weight=class_weight_dict, callbacks=get_callbacks(\"ResNet50_Final\"))\n",
        "\n",
        "#  CLEANUP RESNET50\n",
        "del res_model\n",
        "gc.collect()\n",
        "tf.keras.backend.clear_session()\n",
        "print(\" ResNet50 cleared from memory.\")\n",
        "\n",
        "\n",
        "# --- 2. XCEPTION ---\n",
        "print(\"\\n--- Training Xception ---\")\n",
        "xcp_model, xcp_base = build_model(\"Xception\", (299, 299, 3), NUM_CLASSES)\n",
        "xcp_model.compile(optimizer=Adam(1e-3), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Phase 1: Frozen Backbone\n",
        "xcp_model.fit(train_gen_xcp, validation_data=val_gen_xcp, epochs=20,\n",
        "              class_weight=class_weight_dict, callbacks=get_callbacks(\"Xception_P1\"))\n",
        "\n",
        "# Phase 2: Fine-tuning\n",
        "xcp_base.trainable = True\n",
        "for layer in xcp_base.layers[:100]: layer.trainable = False # Freeze first 100 layers\n",
        "xcp_model.compile(optimizer=Adam(1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "xcp_model.fit(train_gen_xcp, validation_data=val_gen_xcp, epochs=30,\n",
        "              class_weight=class_weight_dict, callbacks=get_callbacks(\"Xception_Final\"))\n",
        "\n",
        "#  CLEANUP XCEPTION\n",
        "del xcp_model\n",
        "gc.collect()\n",
        "tf.keras.backend.clear_session()\n",
        "print(\" Xception cleared from memory.\")\n",
        "\n",
        "\n",
        "# --- 3. EFFICIENTNET-B3 ---\n",
        "print(\"\\n--- Training EfficientNet-B3 ---\")\n",
        "eff_model, eff_base = build_model(\"EffNetB3\", (300, 300, 3), NUM_CLASSES)\n",
        "eff_model.compile(optimizer=Adam(1e-3), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Phase 1: Frozen Backbone\n",
        "eff_model.fit(train_gen_eff, validation_data=val_gen_eff, epochs=20,\n",
        "              class_weight=class_weight_dict, callbacks=get_callbacks(\"EffNetB3_P1\"))\n",
        "\n",
        "# Phase 2: Fine-tuning\n",
        "eff_base.trainable = True\n",
        "# EffNet is sensitive; we only unfreeze the top blocks\n",
        "for layer in eff_base.layers[:300]: layer.trainable = False\n",
        "eff_model.compile(optimizer=Adam(1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "eff_model.fit(train_gen_eff, validation_data=val_gen_eff, epochs=30,\n",
        "              class_weight=class_weight_dict, callbacks=get_callbacks(\"EffNetB3_Final\"))\n",
        "\n",
        "#  CLEANUP EFFICIENTNET\n",
        "del eff_model\n",
        "gc.collect()\n",
        "tf.keras.backend.clear_session()\n",
        "print(\" EfficientNet-B3 cleared from memory.\")\n",
        "\n",
        "print(\"\\n All models trained successfully and saved as .h5 files.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56Pn63tDX_Kw",
        "outputId": "87d767dd-14c2-450e-a88b-6ac35b8fa395"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Training ResNet50 ---\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n",
            "Epoch 1/20\n",
            "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 925ms/step - accuracy: 0.1581 - loss: 2.0019\n",
            "Epoch 1: val_accuracy improved from -inf to 0.11191, saving model to ResNet50_P1_best.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m673s\u001b[0m 1s/step - accuracy: 0.1581 - loss: 2.0019 - val_accuracy: 0.1119 - val_loss: 3.7306 - learning_rate: 0.0010\n",
            "Epoch 2/20\n",
            "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 733ms/step - accuracy: 0.1708 - loss: 1.9766\n",
            "Epoch 2: val_accuracy did not improve from 0.11191\n",
            "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m503s\u001b[0m 801ms/step - accuracy: 0.1708 - loss: 1.9766 - val_accuracy: 0.1103 - val_loss: 5.9826 - learning_rate: 0.0010\n",
            "Epoch 3/20\n",
            "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 732ms/step - accuracy: 0.1512 - loss: 2.0041\n",
            "Epoch 3: val_accuracy did not improve from 0.11191\n",
            "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m503s\u001b[0m 800ms/step - accuracy: 0.1512 - loss: 2.0041 - val_accuracy: 0.1103 - val_loss: 6.8638 - learning_rate: 0.0010\n",
            "Epoch 4/20\n",
            "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 752ms/step - accuracy: 0.1570 - loss: 2.0009\n",
            "Epoch 4: val_accuracy did not improve from 0.11191\n",
            "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m516s\u001b[0m 822ms/step - accuracy: 0.1570 - loss: 2.0009 - val_accuracy: 0.1101 - val_loss: 5.0971 - learning_rate: 0.0010\n",
            "Epoch 5/20\n",
            "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 740ms/step - accuracy: 0.1490 - loss: 1.9925\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "\n",
            "Epoch 5: val_accuracy did not improve from 0.11191\n",
            "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m509s\u001b[0m 810ms/step - accuracy: 0.1490 - loss: 1.9925 - val_accuracy: 0.1103 - val_loss: 5.4218 - learning_rate: 0.0010\n",
            "Epoch 6/20\n",
            "\u001b[1m286/628\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m4:13\u001b[0m 741ms/step - accuracy: 0.1900 - loss: 1.9197"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----\n"
      ],
      "metadata": {
        "id": "JySned-Ya_bk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8.  **Late Fusion Ensemble**"
      ],
      "metadata": {
        "id": "zjlQWXH4bA3b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " 8.0: *Late Fusion Ensemble (Weighted Soft Voting)*"
      ],
      "metadata": {
        "id": "PHRGQlFvbPQK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score"
      ],
      "metadata": {
        "id": "zUSmpTyrbhLe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 9.1. Load Best Saved Models\n",
        "print(\"Loading models for ensemble...\")\n",
        "res_model = load_model(\"ResNet50_Final_best.h5\")\n",
        "xcp_model = load_model(\"Xception_Final_best.h5\")\n",
        "eff_model = load_model(\"EffNetB3_Final_best.h5\")\n",
        "\n",
        "# 9.2. Generate Probabilities (PREDICTION ON TEST SET)\n",
        "print(\"Generating predictions from Test Set...\")\n",
        "pred_res = res_model.predict(test_gen_res, verbose=1)\n",
        "pred_xcp = xcp_model.predict(test_gen_xcp, verbose=1)\n",
        "pred_eff = eff_model.predict(test_gen_eff, verbose=1)\n",
        "\n",
        "# 9.3. Weighted Soft Voting Logic\n",
        "# final_prediction = (pred_ResNet + pred_Xception + pred_EffNet) / 3\n",
        "# Note: Using weights 0.3, 0.3, 0.4 for SOTA optimization\n",
        "w_res, w_xcp, w_eff = 0.30, 0.30, 0.40\n",
        "pred_weighted_avg = (w_res * pred_res) + (w_xcp * pred_xcp) + (w_eff * pred_eff)\n",
        "\n",
        "# Convert probabilities to final class labels\n",
        "y_pred = np.argmax(pred_weighted_avg, axis=1)\n",
        "y_true = np.argmax(y_test_oh, axis=1)\n",
        "\n",
        "print(\" Late Fusion predictions completed.\")"
      ],
      "metadata": {
        "id": "HmEnjZZKbAII"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "----"
      ],
      "metadata": {
        "id": "QxDG_TxKc45m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**9. ENSEMBLE PREDICTION & FINAL EVALUATION**"
      ],
      "metadata": {
        "id": "i28gn460c6Ax"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score, classification_report\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 10.1. Calculate Core Metrics (Macro)\n",
        "accuracy  = accuracy_score(y_true, y_pred)\n",
        "precision = precision_score(y_true, y_pred, average='macro')\n",
        "recall    = recall_score(y_true, y_pred, average='macro')\n",
        "f1        = f1_score(y_true, y_pred, average='macro')\n",
        "\n",
        "# 10.2. Professional Performance Summary\n",
        "print(\"=\"*45)\n",
        "print(f\" FINAL SOTA ENSEMBLE PERFORMANCE\")\n",
        "print(\"=\"*45)\n",
        "print(f\"Accuracy  : {accuracy*100:.2f}%\")\n",
        "print(f\"Precision : {precision*100:.2f}% (Macro)\")\n",
        "print(f\"Recall    : {recall*100:.2f}% (Macro)\")\n",
        "print(f\"F1-Score  : {f1*100:.2f}% (Macro)\")\n",
        "print(\"=\"*45)\n",
        "\n",
        "# 10.3. Per-Class Detail (Precision, Recall, F1 per Emotion)\n",
        "print(\"\\n--- Detailed Classification Report ---\")\n",
        "print(classification_report(y_true, y_pred, target_names=label_encoder.classes_))\n",
        "\n",
        "# 10.4. Confusion Matrix Visualization\n",
        "plt.figure(figsize=(12, 9))\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Purples',\n",
        "            xticklabels=label_encoder.classes_,\n",
        "            yticklabels=label_encoder.classes_)\n",
        "plt.xlabel('Predicted Emotion', fontsize=12)\n",
        "plt.ylabel('True Emotion', fontsize=12)\n",
        "plt.title(f'Final Ensemble Confusion Matrix\\nAccuracy: {accuracy*100:.2f}%', fontsize=15)\n",
        "plt.show()\n",
        "\n",
        "# 10.5. ROC-AUC (One-vs-Rest)\n",
        "try:\n",
        "    auc_score = roc_auc_score(y_test_oh, pred_weighted_avg, multi_class='ovr')\n",
        "    print(f\" ROC-AUC Score (One-vs-Rest): {auc_score:.4f}\")\n",
        "except Exception as e:\n",
        "    print(f\" ROC-AUC could not be calculated: {e}\")"
      ],
      "metadata": {
        "id": "4VuBvUWBc5Uv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}